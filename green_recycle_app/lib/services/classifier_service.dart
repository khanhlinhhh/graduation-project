import 'dart:typed_data';
import 'package:flutter/material.dart';
import 'package:flutter_vision/flutter_vision.dart';
import 'package:camera/camera.dart';

/// Service for waste classification using YOLOv11 TFLite model
class ClassifierService {
  static final ClassifierService _instance = ClassifierService._internal();
  factory ClassifierService() => _instance;
  ClassifierService._internal();

  final FlutterVision _vision = FlutterVision();
  bool _isModelLoaded = false;

  /// Check if model is loaded
  bool get isModelLoaded => _isModelLoaded;

  /// Load YOLOv11 model
  Future<void> loadModel() async {
    if (_isModelLoaded) return;
    
    try {
      await _vision.loadYoloModel(
        labels: 'assets/images/label.txt',
        modelPath: 'assets/images/best_float32.tflite',
        modelVersion: 'yolov11',
        quantization: false,
        numThreads: 4,  // Increased for better performance
        useGpu: true,   // Enable GPU for faster inference
      );
      _isModelLoaded = true;
      debugPrint('YOLOv11 model loaded successfully');
    } catch (e) {
      debugPrint('Error loading model: $e');
      rethrow;
    }
  }

  /// Process camera frame for real-time detection
  Future<List<DetectionResult>> detectOnFrame(CameraImage cameraImage) async {
    if (!_isModelLoaded) {
      throw Exception('Model not loaded. Call loadModel() first.');
    }

    try {
      final result = await _vision.yoloOnFrame(
        bytesList: cameraImage.planes.map((plane) => plane.bytes).toList(),
        imageHeight: cameraImage.height,
        imageWidth: cameraImage.width,
        iouThreshold: 0.5,       // Higher IOU to reduce duplicate boxes
        confThreshold: 0.25,     // Lower confidence to detect more objects
        classThreshold: 0.3,     // Lower class threshold for better detection
      );
      
      return result.map((item) => DetectionResult.fromYoloResult(item)).toList();
    } catch (e) {
      debugPrint('Error detecting on frame: $e');
      return [];
    }
  }

  /// Process static image for classification
  Future<List<DetectionResult>> detectOnImage(
    Uint8List imageBytes,
    int width,
    int height,
  ) async {
    if (!_isModelLoaded) {
      throw Exception('Model not loaded. Call loadModel() first.');
    }

    try {
      final result = await _vision.yoloOnImage(
        bytesList: imageBytes,
        imageHeight: height,
        imageWidth: width,
        iouThreshold: 0.5,       // Higher IOU to reduce duplicate boxes
        confThreshold: 0.25,     // Lower confidence to detect more objects
        classThreshold: 0.3,     // Lower class threshold for better detection
      );
      
      return result.map((item) => DetectionResult.fromYoloResult(item)).toList();
    } catch (e) {
      debugPrint('Error detecting on image: $e');
      return [];
    }
  }

  /// Close model and release resources
  Future<void> closeModel() async {
    if (_isModelLoaded) {
      await _vision.closeYoloModel();
      _isModelLoaded = false;
      debugPrint('YOLOv11 model closed');
    }
  }
}

/// Detection result from YOLOv11 model
class DetectionResult {
  final String labelEn;       // English label from model
  final String label;         // Vietnamese label
  final double confidence;    // 0.0 - 1.0
  final Rect boundingBox;     // Bounding box coordinates
  final Color categoryColor;  // Color for display
  final String emoji;         // Category emoji
  final List<String> tips;    // Disposal tips in Vietnamese
  final int points;           // Points earned

  DetectionResult({
    required this.labelEn,
    required this.label,
    required this.confidence,
    required this.boundingBox,
    required this.categoryColor,
    required this.emoji,
    required this.tips,
    required this.points,
  });

  /// Create from YOLO result map
  factory DetectionResult.fromYoloResult(Map<String, dynamic> result) {
    final tag = result['tag'] as String;
    final box = result['box'] as List<dynamic>;
    
    // box format: [x1:left, y1:top, x2:right, y2:bottom, confidence]
    final x1 = (box[0] as num).toDouble();
    final y1 = (box[1] as num).toDouble();
    final x2 = (box[2] as num).toDouble();
    final y2 = (box[3] as num).toDouble();
    final conf = (box[4] as num).toDouble();

    final categoryInfo = _getCategoryInfo(tag);

    return DetectionResult(
      labelEn: tag,
      label: categoryInfo['label'] as String,
      confidence: conf,
      boundingBox: Rect.fromLTRB(x1, y1, x2, y2),
      categoryColor: categoryInfo['color'] as Color,
      emoji: categoryInfo['emoji'] as String,
      tips: categoryInfo['tips'] as List<String>,
      points: categoryInfo['points'] as int,
    );
  }

  /// Get category information based on English label
  static Map<String, dynamic> _getCategoryInfo(String labelEn) {
    final lowerLabel = labelEn.toLowerCase().trim();
    
    if (lowerLabel.contains('inorganic')) {
      return {
        'label': 'R√°c v√¥ c∆°',
        'color': Colors.grey.shade600,
        'emoji': 'üóëÔ∏è',
        'points': 5,
        'tips': [
          'R·ª≠a s·∫°ch v√† l√†m kh√¥ tr∆∞·ªõc khi b·ªè',
          'Ph√¢n lo·∫°i ri√™ng kim lo·∫°i, nh·ª±a c·ª©ng, th·ªßy tinh',
          'B·ªè v√†o th√πng r√°c v√¥ c∆° (m√†u x√°m)',
          'Kh√¥ng ƒë·ªï chung v·ªõi r√°c h·ªØu c∆°',
        ],
      };
    } else if (lowerLabel.contains('organic')) {
      return {
        'label': 'R√°c h·ªØu c∆°',
        'color': Colors.brown.shade600,
        'emoji': 'üçÇ',
        'points': 5,
        'tips': [
          'ƒê·ªÉ ri√™ng th·ª©c ƒÉn th·ª´a, v·ªè tr√°i c√¢y',
          'C√≥ th·ªÉ ·ªß l√†m ph√¢n compost',
          'B·ªè v√†o th√πng r√°c h·ªØu c∆° (m√†u xanh l√°)',
          'Kh√¥ng ƒë·ªÉ l·∫´n v·ªõi t√∫i nilon',
        ],
      };
    } else if (lowerLabel.contains('recyclable')) {
      return {
        'label': 'R√°c t√°i ch·∫ø',
        'color': const Color(0xFF4CAF50),
        'emoji': '‚ôªÔ∏è',
        'points': 10,
        'tips': [
          'R·ª≠a s·∫°ch v√† l√†m kh√¥',
          'B√≥p d·∫πp chai nh·ª±a, lon ƒë·ªÉ ti·∫øt ki·ªám kh√¥ng gian',
          'G·ª° b·ªè nh√£n d√°n n·∫øu c√≥ th·ªÉ',
          'B·ªè v√†o th√πng r√°c t√°i ch·∫ø (m√†u xanh d∆∞∆°ng)',
        ],
      };
    } else if (lowerLabel.contains('hazardous')) {
      return {
        'label': 'R√°c nguy h·∫°i',
        'color': Colors.red.shade600,
        'emoji': '‚ò¢Ô∏è',
        'points': 15,
        'tips': [
          'KH√îNG b·ªè chung v·ªõi r√°c sinh ho·∫°t',
          'ƒê·ª±ng trong h·ªôp k√≠n, d√°n nh√£n c·∫£nh b√°o',
          'Mang ƒë·∫øn ƒëi·ªÉm thu gom r√°c nguy h·∫°i',
          'Bao g·ªìm: pin, b√≥ng ƒë√®n, h√≥a ch·∫•t, thu·ªëc h·∫øt h·∫°n',
        ],
      };
    }

    // Default fallback
    return {
      'label': labelEn,
      'color': Colors.grey,
      'emoji': '‚ùì',
      'points': 5,
      'tips': [
        'Ph√¢n lo·∫°i c·∫©n th·∫≠n tr∆∞·ªõc khi b·ªè',
        'Tham kh·∫£o h∆∞·ªõng d·∫´n ph√¢n lo·∫°i r√°c ƒë·ªãa ph∆∞∆°ng',
      ],
    };
  }
}

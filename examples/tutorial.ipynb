{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO11 Tutorial",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <a href=\"https://ultralytics.com/yolo\" target=\"_blank\">\n",
        "    <img width=\"1024\" src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\">\n",
        "  </a>\n",
        "\n",
        "  [ä¸­æ–‡](https://docs.ultralytics.com/zh/) | [í•œêµ­ì–´](https://docs.ultralytics.com/ko/) | [æ—¥æœ¬èª](https://docs.ultralytics.com/ja/) | [Ğ ÑƒÑÑĞºĞ¸Ğ¹](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [FranÃ§ais](https://docs.ultralytics.com/fr/) | [EspaÃ±ol](https://docs.ultralytics.com/es/) | [PortuguÃªs](https://docs.ultralytics.com/pt/) | [TÃ¼rkÃ§e](https://docs.ultralytics.com/tr/) | [Tiáº¿ng Viá»‡t](https://docs.ultralytics.com/vi/) | [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](https://docs.ultralytics.com/ar/)\n",
        "\n",
        "  <a href=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml\"><img src=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml/badge.svg\" alt=\"Ultralytics CI\"></a>\n",
        "  <a href=\"https://console.paperspace.com/github/ultralytics/ultralytics\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"/></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "  <a href=\"https://www.kaggle.com/models/ultralytics/yolo11\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "\n",
        "  <a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n",
        "  <a href=\"https://community.ultralytics.com\"><img alt=\"Ultralytics Forums\" src=\"https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.ultralytics.com&logo=discourse&label=Forums&color=blue\"></a>\n",
        "  <a href=\"https://reddit.com/r/ultralytics\"><img alt=\"Ultralytics Reddit\" src=\"https://img.shields.io/reddit/subreddit-subscribers/ultralytics?style=flat&logo=reddit&logoColor=white&label=Reddit&color=blue\"></a>\n",
        "</div>\n",
        "\n",
        "This **Ultralytics Colab Notebook** is the easiest way to get started with [YOLO models](https://www.ultralytics.com/yolo)â€”no installation needed. Built by [Ultralytics](https://www.ultralytics.com/), the creators of YOLO, this notebook walks you through running **state-of-the-art** models directly in your browser.\n",
        "\n",
        "Ultralytics models are constantly updated for performance and flexibility. They're **fast**, **accurate**, and **easy to use**, and they excel at [object detection](https://docs.ultralytics.com/tasks/detect/), [tracking](https://docs.ultralytics.com/modes/track/), [instance segmentation](https://docs.ultralytics.com/tasks/segment/), [image classification](https://docs.ultralytics.com/tasks/classify/), and [pose estimation](https://docs.ultralytics.com/tasks/pose/).\n",
        "\n",
        "Find detailed documentation in the [Ultralytics Docs](https://docs.ultralytics.com/). Get support via [GitHub Issues](https://github.com/ultralytics/ultralytics/issues/new/choose). Join discussions on [Discord](https://discord.com/invite/ultralytics), [Reddit](https://www.reddit.com/r/ultralytics/), and the [Ultralytics Community Forums](https://community.ultralytics.com/)!\n",
        "\n",
        "Request an Enterprise License for commercial use at [Ultralytics Licensing](https://www.ultralytics.com/license).\n",
        "\n",
        "<br>\n",
        "<div>\n",
        "  <a href=\"https://www.youtube.com/watch?v=ZN3nRZT7b24\" target=\"_blank\">\n",
        "    <img src=\"https://img.youtube.com/vi/ZN3nRZT7b24/maxresdefault.jpg\" alt=\"Ultralytics Video\" width=\"640\" style=\"border-radius: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\">\n",
        "  </a>\n",
        "\n",
        "  <p style=\"font-size: 16px; font-family: Arial, sans-serif; color: #555;\">\n",
        "    <strong>Watch: </strong> How to Train\n",
        "    <a href=\"https://github.com/ultralytics/ultralytics\">Ultralytics</a>\n",
        "    <a href=\"https://docs.ultralytics.com/models/yolo11/\">YOLO11</a> Model on Custom Dataset using Google Colab Notebook ğŸš€\n",
        "  </p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://clickpy.clickhouse.com/dashboard/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4de5a5c9-d3b5-4e4e-a4e5-cd80f159e4ce"
      },
      "source": [
        "!uv pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.187 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 39.0/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# 1. Predict\n",
        "\n",
        "YOLO11 may be used directly in the Command Line Interface (CLI) with a `yolo` command for a variety of tasks and modes and accepts additional arguments, i.e. `imgsz=640`. See a full list of available `yolo` [arguments](https://docs.ultralytics.com/usage/cfg/) and other details in the [YOLO11 Predict Docs](https://docs.ultralytics.com/modes/train/).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec201724-e502-46dc-b028-00b59520a8c2"
      },
      "source": [
        "# Run inference on an image with YOLO11n\n",
        "!yolo predict model=yolo11n.pt source='https://ultralytics.com/images/zidane.jpg'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: yolo: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkAzDWJ7cWTr"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/212889447-69e5bdf1-5800-4e29-835e-2ed2336dede2.jpg\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eq1SMWl6Sfn"
      },
      "source": [
        "# 2. Val\n",
        "Validate a model's accuracy on the [COCO](https://docs.ultralytics.com/datasets/detect/coco/) dataset's `val` or `test` splits. The latest YOLO11 [models](https://github.com/ultralytics/ultralytics#models) are downloaded automatically the first time they are used. See [YOLO11 Val Docs](https://docs.ultralytics.com/modes/val/) for more information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQPtK1QYVaD_"
      },
      "source": [
        "# Download COCO val\n",
        "from ultralytics.utils.downloads import download\n",
        "\n",
        "download('https://ultralytics.com/assets/coco2017val.zip', unzip=True, dir='datasets') # download (780MB - 5000 images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X58w8JLpMnjH",
        "outputId": "27364fde-3aff-47ea-9458-18e4a044e27b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Validate YOLO11n on COCO8 val\n",
        "!yolo val model=yolo11n.pt data=coco8.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.187 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "\n",
            "WARNING âš ï¸ Dataset 'coco8.yaml' images not found, missing path '/content/datasets/coco8/images/val'\n",
            "Downloading https://ultralytics.com/assets/coco8.zip to '/content/datasets/coco8.zip': 100% â”â”â”â”â”â”â”â”â”â”â”â” 432.8/432.8KB 12.2MB/s 0.0s\n",
            "Unzipping /content/datasets/coco8.zip to /content/datasets/coco8...: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 4962.5files/s 0.0s\n",
            "Dataset download success âœ… (0.6s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1/755.1KB 22.0MB/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1486.2Â±504.6 MB/s, size: 54.0 KB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 118.2it/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco8/labels/val.cache\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 0.88it/s 1.1s\n",
            "                   all          4         17       0.57       0.85      0.847      0.632\n",
            "                person          3         10      0.557        0.6      0.585      0.272\n",
            "                   dog          1          1      0.548          1      0.995      0.697\n",
            "                 horse          1          2      0.531          1      0.995      0.674\n",
            "              elephant          1          2      0.371        0.5      0.516      0.256\n",
            "              umbrella          1          1      0.569          1      0.995      0.995\n",
            "          potted plant          1          1      0.847          1      0.995      0.895\n",
            "Speed: 0.3ms preprocess, 18.1ms inference, 0.0ms loss, 21.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY2VXXXu74w5"
      },
      "source": [
        "# 3. Train\n",
        "\n",
        "<p align=\"\"><a href=\"https://ultralytics.com/hub\"><img width=\"1000\" src=\"https://github.com/ultralytics/assets/raw/main/yolov8/banner-integrations.png\"/></a></p>\n",
        "\n",
        "Train YOLO11 on [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/) datasets. See [YOLO11 Train Docs](https://docs.ultralytics.com/modes/train/) for more information."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select YOLO11 ğŸš€ logger {run: 'auto'}\n",
        "logger = 'TensorBoard' #@param ['TensorBoard', 'Weights & Biases']\n",
        "\n",
        "if logger == 'TensorBoard':\n",
        "  !yolo settings tensorboard=True\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir .\n",
        "elif logger == 'Weights & Biases':\n",
        "  !yolo settings wandb=True"
      ],
      "metadata": {
        "id": "ktegpM42AooT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. Link colab vá»›i Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5SUl8OdwOT_",
        "outputId": "b1837c6a-16c1-4ea3-8e90-4c798a0f0a37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ppUkV9W_wl50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HGXJa-GSxiHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "040d7720",
        "outputId": "9f6170ed-ad45-4d16-afd1-9d12fa97c576"
      },
      "source": [
        "import os\n",
        "\n",
        "source_path = 'Waster-6' # Corrected path\n",
        "destination_path = '.' # Current directory, which is /content/drive/MyDrive\n",
        "\n",
        "if os.path.exists(source_path):\n",
        "    # The directory is already in the current working directory, so the move is redundant.\n",
        "    # We can skip the 'mv' command if the destination is the same as the source's parent.\n",
        "    # If you intend to move it *into* a subdirectory within MyDrive, please specify that subdirectory.\n",
        "    print(f\"Directory '{source_path}' is already in '{os.path.abspath(destination_path)}'. No move needed.\")\n",
        "else:\n",
        "    print(f\"Source directory '{source_path}' does not exist. Please check the path.\")\n",
        "\n",
        "# Verify the contents of the current directory\n",
        "print(\"\\nListing contents of the current directory ('/content/drive/MyDrive'):\")\n",
        "!ls -F"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'Waster-6' is already in '/content/drive/MyDrive'. No move needed.\n",
            "\n",
            "Listing contents of the current directory ('/content/drive/MyDrive'):\n",
            "'1 (1).gdoc'\n",
            " 15.gdoc\n",
            " 1664024868-bao-cao-de-cuong-do-an-co-so-2.gdoc\n",
            " 1683179291-bao-cao-do-an-co-so-2-tran-viet-doan-21it336.gdoc\n",
            "'18_NGUYEÌ‚ÌƒN KHAÌNH LINH_21IT358.jpg'\n",
            "'1. ÄeÌ‚Ì€ cuÌ›oÌ›ng chi tieÌ‚Ìt ThuÌ›Ì£c taÌ£Ì‚p.gdoc'\n",
            " 1.gdoc\n",
            "'1 laÌ‚Ì€n xem 5k.gdoc'\n",
            " 20230517_191151.mp4\n",
            " 20240524_151445.jpg\n",
            "'20240830-KTPM8- Testing in the Software Developement Life Cycle (SDLC).gdoc'\n",
            " 20241219_213343.jpg\n",
            " 21IT300_Truongthiminhphuong_Lab5.1-IO_Exercise.gdoc\n",
            " 21IT358_21IT194_21IT296_LTHTNhom6.docx\n",
            " 21IT358.docx\n",
            " 21IT358.m4a\n",
            "'21IT358-NguyeÌ‚Ìƒn KhaÌnh Linh-BT tuaÌ‚Ì€n13.docx'\n",
            "'21IT358_NguyeÌ‚Ìƒn KhaÌnh Linh_BT tuaÌ‚Ì€n 5.docx'\n",
            " 21IT358_NguyeÌ‚Ìƒn-KhaÌnh-Linh_BT-tuaÌ‚Ì€n-6.docx\n",
            "'21IT358_NguyeÌ‚Ìƒn KhaÌnh Linh_BT tuaÌ‚Ì€n 7.docx'\n",
            "'21IT358_NguyeÌ‚Ìƒn KhaÌnh Linh_GK (4).docx'\n",
            "'21IT358_NguyeÌ‚Ìƒn KhaÌnh Linh_GK.docx'\n",
            "'21IT358_NguyeÌ‚Ìƒn KhaÌnh Linh_GK.gdoc'\n",
            "'21IT358_NguyeÌ‚Ìƒn KhaÌnh Linh.jpg'\n",
            "'21IT358_NguyeÌ‚Ìƒn KhaÌnh Linh.rar'\n",
            " 2-4-9-21IT358-NguyenKhanhLinh.jpg\n",
            " 29c6fa1b-336c-4ffe-b221-32985480f855.rar\n",
            " 3-4-9-21IT358-NguyenKhanhLinh.jpg\n",
            "'36_NguyeÌ‚Ìƒn KhaÌnh Linh_21SE5.rar'\n",
            "'37-nguyeÌ‚Ìƒn khaÌnh linh baÌ€i1.jpg'\n",
            "'37- nguyeÌ‚Ìƒn khaÌnh linh baÌ€i 2.jpg'\n",
            "'37-nguyeÌ‚Ìƒn khaÌnh linh bai3(de).jpg'\n",
            "'37-nguyeÌ‚Ìƒn khaÌnh linh baÌ€i 3.jpg'\n",
            " 3.gdoc\n",
            " 406503422_337048515605296_894097449074848067_n.jpg\n",
            " 4-4-9-21IT358-NguyenKhanhLinh.jpg\n",
            " 999.jpg\n",
            " AI.gdoc\n",
            " bai3.pkt\n",
            " baÌ€i-giaÌ‰ng-TTHCM-019.gslides\n",
            "'baikiemtra (1).gdoc'\n",
            " baikiemtra.gdoc\n",
            " baithuhoach.docx\n",
            " BaÌ€i-thu-hoaÌ£ch-TSHCD.docx\n",
            "'BaÌ‰n sao cuÌ‰a MaÌ‚Ìƒu Ä‘oÌ›n Ä‘aÌ†ng kiÌ duÌ›Ì£ thi TADR_keÌ€m TB soÌ‚Ì 1.docx'\n",
            "'BaÌ‰n sao cuÌ‰a MaÌ‚Ìƒu Ä‘oÌ›n Ä‘aÌ†ng kiÌ duÌ›Ì£ thi TADR_keÌ€m TB soÌ‚Ì 1.gdoc'\n",
            " BaÌo-caÌo-baÌ€i-lab-3.gdoc\n",
            "'BaÌo caÌo BaÌ€i taÌ£Ì‚p cuoÌ‚Ìi kyÌ€.gdoc'\n",
            " BAÌO-CAÌO-CUOÌ‚ÌI-KIÌ€.gdoc\n",
            " BaoCaoDA3.gdoc\n",
            " BaoCao_DACS3.gdoc\n",
            " baocaodoancoso1.docx\n",
            "'BAÌO CAÌO.docx'\n",
            "'BAÌO CAÌO HOÌ£C SAÌ‚U.gdoc'\n",
            "'BaÌo caÌo Kho duÌ›Ìƒ lieÌ£Ì‚u_final (1).gdoc'\n",
            "'BaÌo caÌo Kho duÌ›Ìƒ lieÌ£Ì‚u_final (2).gdoc'\n",
            "'BaÌo caÌo Kho duÌ›Ìƒ lieÌ£Ì‚u_final (3).gdoc'\n",
            "'BaÌo caÌo Kho duÌ›Ìƒ lieÌ£Ì‚u_final.gdoc'\n",
            "'BAÌO CAÌO _ MOÌ‚ HIÌ€NH ELMO _ HOÌ£C SAÌ‚U 03.gdoc'\n",
            "'BaÌo caÌo QuaÌ‰n triÌ£ duÌ›Ì£ aÌn phaÌ‚Ì€n meÌ‚Ì€m_Final (1).gdoc'\n",
            "'BaÌo caÌo QuaÌ‰n triÌ£ duÌ›Ì£ aÌn phaÌ‚Ì€n meÌ‚Ì€m_Final.gdoc'\n",
            "'BaoCaoVDK (1).gdoc'\n",
            " BaoCaoVDK.gdoc\n",
            " bcÄ‘cÄ‘acn3.gdoc\n",
            " BIDV_1733825132539.jpg\n",
            " BMATT.gdoc\n",
            " BM_TV.gdoc\n",
            " chaÌ‚n-lyÌ-cuoÌ£Ì‚c-Ä‘oÌ›Ì€i2.gdoc\n",
            " chaÌ‚n-lyÌ-cuoÌ£Ì‚c-Ä‘oÌ›Ì€i.gdoc\n",
            " CHAPTER1.gslides\n",
            "'CHAPTER 2.gslides'\n",
            "'ChuÌ›oÌ›ng 3. ToÌ‚Ì‰ hoÌ›Ì£p.gdoc'\n",
            "'ChuÌ›oÌ›ng 3. ToÌ‚Ì‰ hoÌ›Ì£p.pdf'\n",
            "'ChuÌ›oÌ›ng 4. Mot so bai toan co ban.gdoc'\n",
            "'ChuÌ›oÌ›ng 4. Mot so bai toan co ban.pdf'\n",
            "'ChuÌ›oÌ›ng 6. MaÌy Turing.pdf'\n",
            "'ChuyeÌ‚n Ä‘eÌ‚Ì€.gdoc'\n",
            " Classroom/\n",
            " CNXH.gdoc\n",
            "'Colab Notebooks'/\n",
            " ComputerNetwork_C3_en.pptx\n",
            " congnghephanmem.gdoc\n",
            "'Copy of AI_2021_De-thi-T1.docx'\n",
            "'Copy of AI_2021_De-thi-T3.docx'\n",
            "'Copy of BaÌo caÌo QuaÌ‰n triÌ£ duÌ›Ì£ aÌn phaÌ‚Ì€n meÌ‚Ì€m_Final (ChuÌ›a format) (1).docx'\n",
            "'Copy of BaÌo caÌo QuaÌ‰n triÌ£ duÌ›Ì£ aÌn phaÌ‚Ì€n meÌ‚Ì€m_Final (ChuÌ›a format) (2).docx'\n",
            "'Copy of BaÌo caÌo QuaÌ‰n triÌ£ duÌ›Ì£ aÌn phaÌ‚Ì€n meÌ‚Ì€m_Final (ChuÌ›a format) (3).docx'\n",
            "'Copy of BaÌo caÌo QuaÌ‰n triÌ£ duÌ›Ì£ aÌn phaÌ‚Ì€n meÌ‚Ì€m_Final (ChuÌ›a format).docx'\n",
            "'Copy of Blue, Pink, Yellow and Green Cute Illustrative E-Learning Presentation.gslides'\n",
            "'Copy of Cream, Green, and Black Geometric Blocks Clean Minimal Presentation .gslides'\n",
            "'Copy of Happy National Womenâ€™s History Month.gslides'\n",
            "'Copy of Linux vaÌ€ phaÌ‚Ì€n meÌ‚Ì€m moÌ›Ì‰ (6) (1).xlsx'\n",
            "'Copy of Linux vaÌ€ phaÌ‚Ì€n meÌ‚Ì€m moÌ›Ì‰ (6) (2).xlsx'\n",
            "'Copy of Linux vaÌ€ phaÌ‚Ì€n meÌ‚Ì€m moÌ›Ì‰ (6).xlsx'\n",
            "'DA-7-WhiteBox testing.gform'\n",
            " DACN3/\n",
            " DACS1/\n",
            " dacs3/\n",
            " DACS3/\n",
            "'ÄaÌ£i tuÌ›Ì€.gdoc'\n",
            "'Danh saÌch thaÌ€nh vieÌ‚n.docx'\n",
            "'Danh saÌch thaÌ€nh vieÌ‚n.gdoc'\n",
            " data/\n",
            "'Ä‘aÌ‚y moÌ›Ìi laÌ€ chaÌ‚n lyÌ neÌ€.gdoc'\n",
            " De-cuong-chi-tiet3nkl.gdoc\n",
            "'ÄeÌ‚Ì€ cuÌ›oÌ›ng chi tieÌ‚Ìt Ä‘oÌ‚Ì€ aÌn, khoÌa luaÌ£Ì‚n toÌ‚Ìt nghieÌ£Ì‚p.gdoc'\n",
            " ÄEÌ‚Ì€-CUÌ›OÌ›NG-ÄOÌ‚Ì€-AÌN-COÌ›-SOÌ›Ì‰-3_huyÌ€nh-thiÌ£-hoaaaa.gdoc\n",
            "'ÄEÌ‚Ì€ KIEÌ‚Ì‰M TRA GIUÌ›ÌƒA KYÌ€ MAÌ£NG MAÌY TIÌNH (1).docx'\n",
            "'Ä‘eÌ‚Ìn ngaÌ€y 14 12.gsheet'\n",
            "'(ÄeÌ‚Ì€ soÌ‚Ì 1).gdoc'\n",
            " Doan1.zip\n",
            "'ÄoaÌ€n phiÌ'\n",
            " E12.gdoc\n",
            " ELMo.gdoc\n",
            " Essay.gdoc\n",
            " Exercise4-FileManagement.gdoc\n",
            " final/\n",
            " git.gdoc\n",
            " HCM-CHUONG-II-COÌ›-SOÌ›Ì‰-QUAÌ-TRIÌ€NH-HIÌ€NH-THAÌ€NH-PHAÌT-TRIEÌ‚Ì‰N-TTHCM.gslides\n",
            "'hiÌ€nh (1).gdoc'\n",
            " hiÌ€nh.gdoc\n",
            " HTML.rar\n",
            " ideaIU-2025.2.1.exe\n",
            " IMG_2560.jpeg\n",
            " inbound5071497140671213330.jpg\n",
            " java/\n",
            " KhanhLinh_15.rar\n",
            " Khanh-Linh-Nguyen-TopCV.vn-131123.223039.pdf\n",
            "'kho duÌ›Ìƒ lieÌ£Ì‚u'/\n",
            "'kho duÌ›Ìƒ lieÌ£Ì‚u.gdoc'\n",
            "'kieÌ‚Ì‰m thuÌ›Ì‰'/\n",
            "'KN&DMST'/\n",
            " KNDMST5_EAGLE_Ä‘s.pptx\n",
            "'KTPM-10-Static, dynamic testing-Graybox testing-Test report.gform'\n",
            "'KTPM 6-Equivlent class testing .gform'\n",
            "'KTPM 8-WhiteBox Testing.gform'\n",
            "'KTPM-9-BlackBox Testing-Equivalence Class Testing.gform'\n",
            " LAB2HTML_NKL.rar\n",
            " Lab2html.rar\n",
            " Lab3.gdoc\n",
            "'Lab 4 Phan hoach dia chi IP.gdoc'\n",
            " Lab-6-Phan-tich-goi-tin.gdoc\n",
            " labelmap.txt\n",
            " LeThiHongQuy_BaoCao_TTTN.gdoc\n",
            " LICENSE\n",
            " LiÌ£ch.gsheet\n",
            " linux.gdoc\n",
            "'LoÌ›Ìp 6.gdoc'\n",
            " LSÄCSVN.gdoc\n",
            "'MaÌ‚Ìƒu 2 - ÄeÌ‚Ì€ cuÌ›oÌ›ng chi tieÌ‚Ìt Ä‘oÌ‚Ì€ aÌn, khoÌa luaÌ£Ì‚n toÌ‚Ìt nghieÌ£Ì‚p.gdoc'\n",
            " Messenger_creation_41CEC012-8FDE-4496-96E1-9A476FAF219F.jpeg\n",
            "'mmt-qb-2203-1-1 (1).gdoc'\n",
            " mmt-qb-2203-1-1.gdoc\n",
            " models/\n",
            " Ngan-hang-cau-hoi-Mang-May-Tinh-20202021.gdoc\n",
            "'Ngan-hang-cau-hoi-Mang-May-Tinh-20202021-tienganh (1).gdoc'\n",
            " Ngan-hang-cau-hoi-Mang-May-Tinh-20202021-tienganh.gdoc\n",
            "'Ngan hang cau hoi Mang May Tinh 2023.gdoc'\n",
            "'NguyeÌ‚Ìƒn_KhaÌnh_Linh_21IT258_BT_tuaÌ‚Ì€n 9.docx'\n",
            "'NguyeÌ‚Ìƒn KhaÌnh Linh_21IT358 (1).docx'\n",
            "'NguyÌ£enKhanhLinh_21IT358 (1).pdf'\n",
            "'NguyeÌ‚Ìƒn KhaÌnh Linh_21It358 (2).docx'\n",
            "'NguyeÌ‚Ìƒn KhaÌnh Linh -21it358 - bt3 (1).docx'\n",
            "'NguyeÌ‚Ìƒn KhaÌnh Linh -21it358 - bt3.docx'\n",
            " NguyeÌ‚Ìƒn_KhaÌnh_Linh_21IT358_bt_tuaÌ‚Ì€n10.docx\n",
            "'NguyenKhanhLinh-21IT358- BTTuaÌ‚Ì€n14.docx'\n",
            " Nguyen_Khanh_Linh_21IT358_BT_tuan_2.docx\n",
            " NguyeÌ‚Ìƒn_KhaÌnh_Linh_21IT358_BT-tuaÌ‚Ì€n8.docx\n",
            "'NguyeÌ‚Ìƒn KhaÌnh Linh_21IT358.docx'\n",
            "'NguyeÌ‚Ìƒn KhaÌnh Linh_21IT358.gdoc'\n",
            "'NguyeÌ‚Ìƒn KhaÌnh Linh_21IT358.jpg'\n",
            " NguyenKhanhLinh_21IT358_Lab2.pdf\n",
            " NguyenKhanhLinh_21IT358_Lab3.pdf\n",
            "'NguyeÌ‚Ìƒn KhaÌnh Linh_21IT358 NguyeÌ‚Ìƒn ThiÌ£ Lan Anh_21IT189 NguyeÌ‚Ìƒn TheÌ‚Ì Anh_21IT598 HuyÌ€nh TaÌ†ng NhaÌ£Ì‚t Huy_21IT143.xlsx'\n",
            " NguyÌ£enKhanhLinh_21IT358.pdf\n",
            " NguyenKhanhLinh__BaoCao_TTTN.gdoc\n",
            " Nguyen_Khanh_Linh_CV.pdf\n",
            "'NguyeÌ‚Ìƒn KhaÌnh Linh HuyÌ€nh TaÌ†ng NhaÌ£Ì‚t Huy NguyeÌ‚Ìƒn ThiÌ£ Lan Anh.xlsx'\n",
            "'NguyeÌ‚Ìƒn KhaÌnh Linh NguyeÌ‚Ìƒn ThiÌ£ Lan Anh NguyeÌ‚Ìƒn TheÌ‚Ì Anh HuyÌ€nh TaÌ†ng NhaÌ£Ì‚t Huy  (1).xlsx'\n",
            "'NguyeÌ‚Ìƒn KhaÌnh Linh, NguyeÌ‚Ìƒn ThiÌ£ Lan Anh, NguyeÌ‚Ìƒn TheÌ‚Ì Anh, HuyÌ€nh TaÌ†ng NhaÌ£Ì‚t Huy.gsheet'\n",
            "'NhieÌ£Ì‚m vuÌ£ 3 â€” ThieÌ‚Ìt keÌ‚Ì Test Case troÌ£ng yeÌ‚Ìu'$'\\n''Deliver....gsheet'\n",
            " nhom7.pdf\n",
            "'NKLinh - 21IT358- BT TuaÌ‚Ì€n 1 (1).docx'\n",
            "'NKLinh - 21IT358- BT TuaÌ‚Ì€n 1.docx'\n",
            "'OÌ‚n TaÌ‚p.gdoc'\n",
            "'OÌ‚N-TAÌ£Ì‚P-TRIEÌ‚ÌT-HOÌ£C (1).gdoc'\n",
            " Part-6-Test-1TANC.gdoc\n",
            " PLÄC.gdoc\n",
            " pretrained/\n",
            " pv.gdoc\n",
            "'Q1 (2.gdoc'\n",
            " README.md\n",
            "'Screenshot_20230402-214548_Thanh Nin.jpg'\n",
            " shopping/\n",
            " slide.gslides\n",
            " Slide-RoboCar.gslides\n",
            "'SLIDES PDF.rar'\n",
            " SQLCoBan_ThucHanhSQL_DB1_PhanCoBan.gdoc\n",
            "'taÌ‰ caÌ‚y.gdoc'\n",
            " tanc2.gdoc\n",
            "'TEST 5 - RC given to students.pdf'\n",
            "'Test Case.gsheet'\n",
            "'Testcase Template.gsheet'\n",
            "'tieÌ‚Ìng anh.gdoc'\n",
            "'tieÌ‚Ìng vieÌ£Ì‚t 5.gdoc'\n",
            " TNT_21-22-1.gdoc\n",
            " tthcm.gdoc\n",
            " TTTN/\n",
            "'Untitled document (10).gdoc'\n",
            "'Untitled document (11).gdoc'\n",
            "'Untitled document (12).gdoc'\n",
            "'Untitled document (13).gdoc'\n",
            "'Untitled document (14).gdoc'\n",
            "'Untitled document (15).gdoc'\n",
            "'Untitled document (16).gdoc'\n",
            "'Untitled document (17).gdoc'\n",
            "'Untitled document (18).gdoc'\n",
            "'Untitled document (19).gdoc'\n",
            "'Untitled document (1).gdoc'\n",
            "'Untitled document (20).gdoc'\n",
            "'Untitled document (21).gdoc'\n",
            "'Untitled document (22).gdoc'\n",
            "'Untitled document (23).gdoc'\n",
            "'Untitled document (24).gdoc'\n",
            "'Untitled document (25).gdoc'\n",
            "'Untitled document (26).gdoc'\n",
            "'Untitled document (27).gdoc'\n",
            "'Untitled document (28).gdoc'\n",
            "'Untitled document (29).gdoc'\n",
            "'Untitled document (2).gdoc'\n",
            "'Untitled document (30).gdoc'\n",
            "'Untitled document (31).gdoc'\n",
            "'Untitled document (32).gdoc'\n",
            "'Untitled document (33).gdoc'\n",
            "'Untitled document (34).gdoc'\n",
            "'Untitled document (35).gdoc'\n",
            "'Untitled document (36).gdoc'\n",
            "'Untitled document (37).gdoc'\n",
            "'Untitled document (38).gdoc'\n",
            "'Untitled document (39).gdoc'\n",
            "'Untitled document (3).gdoc'\n",
            "'Untitled document (40).gdoc'\n",
            "'Untitled document (41).gdoc'\n",
            "'Untitled document (42).gdoc'\n",
            "'Untitled document (43).gdoc'\n",
            "'Untitled document (44).gdoc'\n",
            "'Untitled document (45).gdoc'\n",
            "'Untitled document (46).gdoc'\n",
            "'Untitled document (47).gdoc'\n",
            "'Untitled document (48).gdoc'\n",
            "'Untitled document (49).gdoc'\n",
            "'Untitled document (4).gdoc'\n",
            "'Untitled document (50).gdoc'\n",
            "'Untitled document (51).gdoc'\n",
            "'Untitled document (52).gdoc'\n",
            "'Untitled document (53).gdoc'\n",
            "'Untitled document (54).gdoc'\n",
            "'Untitled document (55).gdoc'\n",
            "'Untitled document (56).gdoc'\n",
            "'Untitled document (57).gdoc'\n",
            "'Untitled document (58).gdoc'\n",
            "'Untitled document (59).gdoc'\n",
            "'Untitled document (5).gdoc'\n",
            "'Untitled document (60).gdoc'\n",
            "'Untitled document (6).gdoc'\n",
            "'Untitled document (7).gdoc'\n",
            "'Untitled document (8).gdoc'\n",
            "'Untitled document (9).gdoc'\n",
            "'Untitled document.gdoc'\n",
            "'Untitled presentation.gslides'\n",
            "'Untitled spreadsheet (1).gsheet'\n",
            "'Untitled spreadsheet (2).gsheet'\n",
            "'Untitled spreadsheet (3).gsheet'\n",
            "'Untitled spreadsheet (4).gsheet'\n",
            "'Untitled spreadsheet (5).gsheet'\n",
            "'Untitled spreadsheet.gsheet'\n",
            " Waster-6/\n",
            "'web server.gdoc'\n",
            "'z3974958352180_d655de0728d32c5cb9ee59c625cfecf8 (1).jpg'\n",
            " z3974958352180_d655de0728d32c5cb9ee59c625cfecf8.jpg\n",
            "'è¯èªæ–‡èƒ½åŠ›æ¸¬é©—è€ƒè©¦ (1).gsheet'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"maJdq7xFqEGSz2lgVA4S\")\n",
        "project = rf.workspace(\"classification-lfv4e\").project(\"waster-mtgt6\")\n",
        "version = project.version(6)\n",
        "dataset = version.download(\"yolov11\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao-GvpsculoL",
        "outputId": "b7c2576e-5e38-41e3-f2a9-7c8fc2901023"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.11-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.11.12)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Collecting pi-heif<2 (from roboflow)\n",
            "  Downloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.61.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.4)\n",
            "Downloading roboflow-1.2.11-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.1 pillow-avif-plugin-1.5.2 roboflow-1.2.11\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Waster-6 to yolov11:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 321573/321573 [00:18<00:00, 17319.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Waster-6 in yolov11:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9062/9062 [00:01<00:00, 6224.52it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "outputId": "5e1c62ff-0859-43f2-fd3b-92bea0754355",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train YOLO11n on COCO8 for 3 epochs\n",
        "!python -m ultralytics.yolo train model=yolo11n.pt data=/content/drive/MyDrive/Waster-6/data.yaml.yaml epochs=100 imgsz=640"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3: Error while finding module specification for 'ultralytics.yolo' (ModuleNotFoundError: No module named 'ultralytics')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Export\n",
        "\n",
        "Export a YOLO model to any supported format below with the `format` argument, i.e. `format=onnx`. See [Export Docs](https://docs.ultralytics.com/modes/export/) for more information.\n",
        "\n",
        "- ğŸ’¡ ProTip: Export to [ONNX](https://docs.ultralytics.com/integrations/onnx/) or [OpenVINO](https://docs.ultralytics.com/integrations/openvino/) for up to 3x CPU speedup.\n",
        "- ğŸ’¡ ProTip: Export to [TensorRT](https://docs.ultralytics.com/integrations/tensorrt/) for up to 5x GPU speedup.\n",
        "\n",
        "| Format | `format` Argument | Model | Metadata | Arguments |\n",
        "|--------|-----------------|-------|----------|------------|\n",
        "| [PyTorch](https://pytorch.org/) | - | `yolo11n.pt` | âœ… | - |\n",
        "| [TorchScript](https://docs.ultralytics.com/integrations/torchscript) | `torchscript` | `yolo11n.torchscript` | âœ… | `imgsz`, `batch`, `dynamic`, `optimize`, `half`, `nms`, `device` |\n",
        "| [ONNX](https://docs.ultralytics.com/integrations/onnx) | `onnx` | `yolo11n.onnx` | âœ… | `imgsz`, `batch`, `dynamic`, `half`, `opset`, `simplify`, `nms`, `device` |\n",
        "| [OpenVINO](https://docs.ultralytics.com/integrations/openvino) | `openvino` | `yolo11n_openvino_model/` | âœ… | `imgsz`, `batch`, `dynamic`, `half`, `int8`, `nms`, `fraction`, `device`, `data` |\n",
        "| [TensorRT](https://docs.ultralytics.com/integrations/tensorrt) | `engine` | `yolo11n.engine` | âœ… | `imgsz`, `batch`, `dynamic`, `half`, `int8`, `simplify`, `nms`, `fraction`, `device`, `data`, `workspace` |\n",
        "| [CoreML](https://docs.ultralytics.com/integrations/coreml) | `coreml` | `yolo11n.mlpackage` | âœ… | `imgsz`, `batch`, `half`, `int8`, `nms`, `device` |\n",
        "| [TF SavedModel](https://docs.ultralytics.com/integrations/tf-savedmodel) | `saved_model` | `yolo11n_saved_model/` | âœ… | `imgsz`, `batch`, `int8`, `keras`, `nms`, `device` |\n",
        "| [TF GraphDef](https://docs.ultralytics.com/integrations/tf-graphdef) | `pb` | `yolo11n.pb` | âŒ | `imgsz`, `batch`, `device` |\n",
        "| [TF Lite](https://docs.ultralytics.com/integrations/tflite) | `tflite` | `yolo11n.tflite` | âœ… | `imgsz`, `batch`, `half`, `int8`, `nms`, `fraction`, `device`, `data` |\n",
        "| [TF Edge TPU](https://docs.ultralytics.com/integrations/edge-tpu) | `edgetpu` | `yolo11n_edgetpu.tflite` | âœ… | `imgsz`, `device` |\n",
        "| [TF.js](https://docs.ultralytics.com/integrations/tfjs) | `tfjs` | `yolo11n_web_model/` | âœ… | `imgsz`, `batch`, `half`, `int8`, `nms`, `device` |\n",
        "| [PaddlePaddle](https://docs.ultralytics.com/integrations/paddlepaddle) | `paddle` | `yolo11n_paddle_model/` | âœ… | `imgsz`, `batch`, `device` |\n",
        "| [MNN](https://docs.ultralytics.com/integrations/mnn) | `mnn` | `yolo11n.mnn` | âœ… | `imgsz`, `batch`, `half`, `int8`, `device` |\n",
        "| [NCNN](https://docs.ultralytics.com/integrations/ncnn) | `ncnn` | `yolo11n_ncnn_model/` | âœ… | `imgsz`, `batch`, `half`, `device` |\n",
        "| [IMX500](https://docs.ultralytics.com/integrations/sony-imx500) | `imx` | `yolo11n_imx_model/` | âœ… | `imgsz`, `int8`, `fraction`, `device`, `data` |\n",
        "| [RKNN](https://docs.ultralytics.com/integrations/rockchip-rknn) | `rknn` | `yolo11n_rknn_model/` | âœ… | `imgsz`, `batch`, `name`, `device` || [ExecuTorch](https://docs.ultralytics.com/integrations/executorch) | `executorch` | `executorch_model/` | âœ… | `imgsz`, `device` || [Axelera](https://docs.ultralytics.com/integrations/axelera) | `axelera` | `axelera_model/` | âœ… | `imgsz`, `int8`, `fraction`, `device`, `data` |"
      ],
      "metadata": {
        "id": "nPZZeNrLCQG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo export model=yolo11n.pt format=torchscript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYIjW4igCjqD",
        "outputId": "f06e7d97-01d9-45f4-b24b-e90b08291675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.187 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon 2.00GHz)\n",
            "ğŸ’¡ ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
            "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.8.0+cu126...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success âœ… 2.1s, saved as 'yolo11n.torchscript' (10.5 MB)\n",
            "\n",
            "Export complete (2.6s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolo11n.torchscript imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolo11n.torchscript imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
            "Visualize:       https://netron.app\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/export\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Python Usage\n",
        "\n",
        "YOLO11 was reimagined using Python-first principles for the most seamless Python YOLO experience yet. YOLO11 models can be loaded from a trained checkpoint or created from scratch. Then methods are used to train, val, predict, and export the model. See detailed Python usage examples in the [YOLO11 Python Docs](https://docs.ultralytics.com/usage/python/)."
      ],
      "metadata": {
        "id": "kUMOQ0OeDBJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolo11n.yaml')  # build a new model from scratch\n",
        "model = YOLO('yolo11n.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data='coco8.yaml', epochs=3)  # train the model\n",
        "results = model.val()  # evaluate model performance on the validation set\n",
        "results = model('https://ultralytics.com/images/bus.jpg')  # predict on an image\n",
        "results = model.export(format='onnx')  # export the model to ONNX format"
      ],
      "metadata": {
        "id": "bpF9-vS_DAaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Tasks\n",
        "\n",
        "YOLO11 can train, val, predict and export models for the most common tasks in vision AI: [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/). See [YOLO11 Tasks Docs](https://docs.ultralytics.com/tasks/) for more information.\n",
        "\n",
        "<br><img width=\"1024\" src=\"https://raw.githubusercontent.com/ultralytics/assets/main/im/banner-tasks.png\">\n"
      ],
      "metadata": {
        "id": "Phm9ccmOKye5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Detection\n",
        "\n",
        "YOLO11 _detection_ models have no suffix and are the default YOLO11 models, i.e. `yolo11n.pt` and are pretrained on COCO. See [Detection Docs](https://docs.ultralytics.com/tasks/detect/) for full details.\n"
      ],
      "metadata": {
        "id": "yq26lwpYK1lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO11n, train it on COCO128 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolo11n.pt')  # load a pretrained YOLO detection model\n",
        "model.train(data='coco8.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "8Go5qqS9LbC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Segmentation\n",
        "\n",
        "YOLO11 _segmentation_ models use the `-seg` suffix, i.e. `yolo11n-seg.pt` and are pretrained on COCO. See [Segmentation Docs](https://docs.ultralytics.com/tasks/segment/) for full details.\n"
      ],
      "metadata": {
        "id": "7ZW58jUzK66B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO11n-seg, train it on COCO128-seg for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolo11n-seg.pt')  # load a pretrained YOLO segmentation model\n",
        "model.train(data='coco8-seg.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "WFPJIQl_L5HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Classification\n",
        "\n",
        "YOLO11 _classification_ models use the `-cls` suffix, i.e. `yolo11n-cls.pt` and are pretrained on ImageNet. See [Classification Docs](https://docs.ultralytics.com/tasks/classify/) for full details.\n"
      ],
      "metadata": {
        "id": "ax3p94VNK9zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO11n-cls, train it on mnist160 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolo11n-cls.pt')  # load a pretrained YOLO classification model\n",
        "model.train(data='mnist160', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "5q9Zu6zlL5rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Pose\n",
        "\n",
        "YOLO11 _pose_ models use the `-pose` suffix, i.e. `yolo11n-pose.pt` and are pretrained on COCO Keypoints. See [Pose Docs](https://docs.ultralytics.com/tasks/pose/) for full details."
      ],
      "metadata": {
        "id": "SpIaFLiO11TG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO11n-pose, train it on COCO8-pose for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolo11n-pose.pt')  # load a pretrained YOLO pose model\n",
        "model.train(data='coco8-pose.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "si4aKFNg19vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Oriented Bounding Boxes (OBB)\n",
        "\n",
        "YOLO11 _OBB_ models use the `-obb` suffix, i.e. `yolo11n-obb.pt` and are pretrained on the DOTA dataset. See [OBB Docs](https://docs.ultralytics.com/tasks/obb/) for full details."
      ],
      "metadata": {
        "id": "cf5j_T9-B5F0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO11n-obb, train it on DOTA8 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolo11n-obb.pt')  # load a pretrained YOLO OBB model\n",
        "model.train(data='dota8.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/boats.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "IJNKClOOB5YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEijrePND_2I"
      },
      "source": [
        "# Appendix\n",
        "\n",
        "Additional content below."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pip install from source\n",
        "!uv pip install git+https://github.com/ultralytics/ultralytics@main"
      ],
      "metadata": {
        "id": "pIdE6i8C3LYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Git clone and run tests on 'main' branch\n",
        "!git clone https://github.com/ultralytics/ultralytics -b main\n",
        "!uv pip install -qe ultralytics"
      ],
      "metadata": {
        "id": "uRKlwxSJdhd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run tests (Git clone only)\n",
        "!pytest ultralytics/tests"
      ],
      "metadata": {
        "id": "GtPlh7mcCGZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate multiple models\n",
        "for x in 'nsmlx':\n",
        "  !yolo val model=yolo11{x}.pt data=coco.yaml"
      ],
      "metadata": {
        "id": "Wdc6t_bfzDDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}